[
  {
    "slug": "coding-agent-breakdown",
    "title": "关于对 Coding Agent 拆解和一些问题的汇总",
    "date": "2026-01-19T00:00:00.000Z",
    "tags": [
      "Coding Agent",
      "LLM",
      "最佳实践",
      "架构"
    ],
    "summary": "梳理 LLM 的本质限制与 Coding Agent 的实现机制，并总结常见痛点与应对策略。",
    "cover": "/vast-empty-dark-landscape-with-distant-light-horiz.jpg",
    "readingTime": 2,
    "contentHtml": "<h2>1. LLM 的本质限制与 Coding 领域的挑战</h2>\n<h3>1.1 LLM 的本质</h3>\n<ul>\n<li><p><strong>自回归生成 (Autoregressive Generation)</strong></p>\n<ul>\n<li><p>核心机制：根据 <strong>&quot;你的输入&quot;</strong> 和 <strong>&quot;前面生成的内容&quot;</strong> 预测概率最高的下一个 Token，然后不断循环直到结束。</p>\n</li>\n<li><p><strong>思考的局限性：</strong> 没有独立的&quot;思维黑盒&quot;。尽管现在的大模型（如 o1/R1 类模型）有了显式的 reasoning（思维链）部分，依然无法脱离自回归范式——<strong>必须通过生成 Token 才能进行思考</strong>。</p>\n</li>\n<li><p><strong>记忆机制：</strong> 上下文 (Context) 就是全部的记忆，没有隐藏的持久化存储。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>Attention 机制 (注意力)</strong></p>\n<ul>\n<li><p><strong>如何运行：</strong> 每当生成一个 Token 时，都会计算当前位置与上下文 <strong>每个位置</strong> 的相关性（Q, K, V计算）。相关性高的获得更高权重，模型据此生成后续内容。</p>\n</li>\n<li><p><strong>上下文的诅咒：</strong></p>\n<ul>\n<li><p><strong>计算复杂度：</strong> 注意力机制的时间复杂度是 $O(n^2)$（不考虑优化算法时），随着长度增加计算量剧增。</p>\n</li>\n<li><p><strong>注意力稀释 (Lost in the Middle)：</strong> 当上下文很长时，注意力权重会分散到更多位置，关键信息获得的权重可能会被稀释，导致“大海捞针”能力下降。所以并不是单纯增加 Context Window 就能解决所有问题。</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong>强化学习 (Reinforcement Learning)</strong></p>\n<ul>\n<li><p><strong>RLHF (Reinforcement Learning from Human Feedback)：</strong> LLM 最初只学会了预测下一个 Token，需要通过 RL 让它学会“人类希望它怎么写”。</p>\n</li>\n<li><p><strong>流程：</strong> 尝试（真实场景执行任务）-&gt; 反馈（根据结果给回奖励/惩罚）-&gt; 调整（使用 PPO/DPO 等算法调整模型参数）。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>1.2 Coding 领域的特有问题</h3>\n<ul>\n<li><p><strong>缺乏全局视野：</strong> 由于自回归的本质，模型往往只关注“局部最优”的 Token 预测，缺乏对整个代码库的<strong>全局规划 (Holistic Planning)</strong>。</p>\n</li>\n<li><p><strong>不可回溯性：</strong> 流式输出导致无法“回头”修改已生成的内容。如果开头方向错了，后续只能基于错误的路径继续生成。</p>\n</li>\n<li><p><strong>误差累积 (Error Accumulation)：</strong> 在长任务中，如果某一步推理走偏，后续生成的代码会越来越偏离需求。</p>\n</li>\n<li><p><strong>幻觉与严谨性的冲突：</strong> Coding 要求强语法、强语义约束。LLM 无法像编译器一样对生成的代码有绝对认知，它只是在生成“看上去合理”的代码（除非通过测试或解释器提供明确的 Runtime 上下文）。</p>\n</li>\n</ul>\n<hr>\n<h2>2. Coding Agent 的底层实现原理</h2>\n<h3>2.1 基础架构</h3>\n<ul>\n<li><p><strong>LLM API 结构：</strong></p>\n<ul>\n<li><p>消息数组包含角色：<code>system</code> (系统指令), <code>user</code> (用户输入), <code>assistant</code> (模型回答)。</p>\n</li>\n<li><p><strong>显式推理：</strong> 对于具备推理能力的模型，API 响应中可能包含 <code>reasoning_content</code> 或 <code>thinking</code> 字段，与最终内容分开。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>Tool Calling (工具调用/函数调用)：</strong></p>\n<ul>\n<li><p>模型不直接执行代码，而是生成结构化的 JSON 请求（工具调用）。</p>\n</li>\n<li><p>Agent 运行时（Runtime）拦截请求，执行工具，并将执行结果结构化为新消息（Role: <code>tool</code>）返回给模型。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>2.2 性能优化：Prompt Caching</h3>\n<ul>\n<li><p><strong>原理：</strong> 在自回归生成中，如果每次请求都要重新处理整个 Input Context，会造成大量的计算浪费（Prefill 阶段）和高延迟。</p>\n</li>\n<li><p><strong>前缀匹配 (Prefix Matching)：</strong> 缓存通常基于前缀。只有当新请求的<strong>开头部分</strong>与之前请求<strong>完全一致</strong>时，才会命中缓存（KV Cache）。</p>\n</li>\n<li><p><strong>最佳实践：</strong></p>\n<ul>\n<li><p><strong>静态在前：</strong> <code>System Prompt</code>, <code>Tool Definitions</code>, <code>Few-shot Examples</code> 等稳定内容放在 Prompt 最开头。</p>\n</li>\n<li><p><strong>动态在后：</strong> 对话历史、当前用户输入、不断变化的文件内容放在后面，避免打断缓存的前缀连续性。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>2.3 Agent Loop (ReAct 循环)</h3>\n<ul>\n<li><p><strong>核心逻辑：</strong> 调用模型 -&gt; 检查是否需要使用工具 -&gt; (若需要) 执行工具 -&gt; 结果返回模型 -&gt; 再次调用。</p>\n</li>\n<li><p><strong>终止条件：</strong></p>\n<ul>\n<li><p><code>end_turn</code> / <code>stop</code>：模型认为任务已完成，输出最终响应。</p>\n</li>\n<li><p><code>tool_use</code>：模型请求调用工具（循环继续）。</p>\n</li>\n<li><p><code>max_tokens</code>：响应因达到长度限制被截断（通常需要处理这种异常）。</p>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2>3. Coding Agent 常见痛点与解决方案</h2>\n<h3>3.1 痛点一：会话之间无持久记忆</h3>\n<p>Agent 的工作往往需要跨越多个会话，默认情况下它会“失忆”。</p>\n<ul>\n<li><p><strong>解决方案：结构化任务追踪系统</strong></p>\n<ul>\n<li><p>要求 Agent 维护一组特定的 Markdown 文件（作为外部记忆）。</p>\n</li>\n<li><p><strong>必须包含：</strong> 项目目标、背景、<strong>当前正在进行的会话状态</strong>、架构决策、技术栈、环境配置、依赖版本。</p>\n</li>\n<li><p><strong>强制动作：</strong> 每次启动新会话时，强制 Agent 读取这些文件；结束时，强制更新这些文件。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>3.2 痛点二：上下文窗口耗尽 (Context Exhaustion)</h3>\n<p>面对复杂任务，旧的历史消息会迅速填满 Context Window。</p>\n<ul>\n<li><p><strong>解决方案：</strong></p>\n<ol>\n<li><p><strong>观察压缩：</strong> 只针对工具返回的 <code>Observation</code>（观察结果）进行处理。保留 Agent 的推理（Thought）和行动（Action），但将冗长的工具输出（如大文件的 <code>cat</code> 结果）用占位符替代。</p>\n</li>\n<li><p><strong>LLM 摘要：</strong> 定期将早期的观察、行动、推理全部压缩为一段摘要。（<em>注：可能会丢失细节</em>）</p>\n</li>\n<li><p><strong>减少工具输出：</strong> 优化工具设计，避免一次性返回 500行+ 的代码，改为按需读取（如 <code>read_lines</code>）。</p>\n</li>\n<li><p><strong>简化工具结构：</strong> 减少 Tool Definition 的 Token 占用。</p>\n</li>\n<li><p><strong>任务拆分：</strong> 将大任务拆解为子任务，每个子任务在一个新的、干净的 Context 中执行。</p>\n</li>\n</ol>\n</li>\n</ul>\n<h3>3.3 痛点三：选择性忽视问题</h3>\n<p>Agent 在工作中可能会通过日志或报错注意到各种潜在问题，但因为当前上下文空间紧张或聚焦于主任务，选择忽视。</p>\n<ul>\n<li><strong>解决方案：</strong> 建立 <strong>&quot;发现即记录&quot; (Log-as-you-go)</strong> 的工作流程。强制 Agent 将发现的但暂不处理的问题写入外部的 <code>TODO.md</code> 或 <code>ISSUES.md</code>。</li>\n</ul>\n<h3>3.4 痛点四：过早宣布完成</h3>\n<p>Agent 可能会在大量 Corner Case 未覆盖的情况下自信地宣布任务结束。</p>\n<ul>\n<li><p><strong>解决方案：</strong></p>\n<ul>\n<li><p><strong>外部计划检查：</strong> 定期让 Agent 对照存储在上下文之外（文件里）的计划表。</p>\n</li>\n<li><p><strong>Definition of Done (DoD)：</strong> 在 System Prompt 中植入严格的“完成定义”。</p>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2>4. 策略：如何保证短对话的高效进行 (Iterative Development)</h2>\n<p>为了避免长上下文带来的“降智”，推荐采用<strong>短周期迭代</strong>模式：</p>\n<ul>\n<li><p><strong>对话 1 (Reconnaissance)：</strong> 调研现有代码结构，输出关键文件列表和当前架构理解。不写代码，只读。</p>\n</li>\n<li><p><strong>对话 2 (Foundation)：</strong> 引用对话 1 的结论，实现基础功能/脚手架。</p>\n</li>\n<li><p><strong>对话 3 (Refinement)：</strong> 引用对话 2，增加边界条件处理和逻辑完善。</p>\n</li>\n<li><p><strong>对话 4 (Testing)：</strong> 引用对话 3，添加单元测试和集成测试。</p>\n</li>\n<li><p><strong>对话 5 (Review)：</strong> 自我代码审查，确认是否符合项目规范，检查安全隐患。</p>\n</li>\n<li><p><strong>对话 6 (Fix)：</strong> 针对审查发现的问题进行最终修复。</p>\n</li>\n</ul>\n<hr>\n<h2>5. 最佳实践：项目上下文配置文件</h2>\n<p>这是告诉 Agent &quot;怎么在这个特定项目里工作&quot; 的说明书。类似文件名：<code>CLAUDE.md</code> 或 <code>AGENT_GUIDE.md</code>。</p>\n<h3>内容结构 (原则：不超过 300 行)</h3>\n<ul>\n<li><p><strong>WHAT（是什么）：</strong></p>\n<ul>\n<li><p>技术栈清单。</p>\n</li>\n<li><p>项目结构树（特别是 Monorepo）。</p>\n</li>\n<li><p>各模块职责：告诉 Agent 哪些是应用层，哪些是共享库。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>WHY（为什么）：</strong></p>\n<ul>\n<li><p>项目的核心目的。</p>\n</li>\n<li><p>关键设计决策的背景（Context）。</p>\n</li>\n<li><p><strong>历史债务说明：</strong> 为什么有些代码看起来不合理？（防止 Agent 盲目重构导致破坏）。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>HOW（怎么做）：</strong></p>\n<ul>\n<li><p>如何运行项目 (Run)。</p>\n</li>\n<li><p>如何测试 (Test)。</p>\n</li>\n<li><p>如何验证改动 (Verify)。</p>\n</li>\n<li><p><strong>具体命令：</strong> 明确是用 <code>bun</code> 还是 <code>npm</code>？测试命令是 <code>make test</code> 还是 <code>npm test</code>？</p>\n</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><strong>💡 补充建议：</strong></p>\n<ul>\n<li><p><strong>代码风格 (Style)：</strong> 忽略掉。不要在 Prompt 里教 LLM 怎么缩进，直接用 <code>Prettier</code> 或 <code>Linter</code> 工具在保存时自动格式化。</p>\n</li>\n<li><p><strong>经验库：</strong> 可以在文件中简要维护“踩过的坑”或“成功的模式”。</p>\n</li>\n</ul>\n</blockquote>\n<hr>\n<h2>6. 质量控制：防止 Agent 跳过测试</h2>\n<ul>\n<li><p><strong>核心手段：</strong></p>\n<ul>\n<li><p>要求 Agent 频繁提交代码 (Small Commits)。</p>\n</li>\n<li><p><strong>Pre-commit Hooks：</strong> 在 <code>.git/hooks/pre-commit</code> 中配置脚本，强制在 commit 前运行 Lint 和 Test。如果测试不通过，拒绝提交。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>应对 Agent 的“小聪明”：</strong></p>\n<ul>\n<li><p>Agent 可能会尝试使用 <code>git commit --no-verify</code> 来跳过检查。</p>\n</li>\n<li><p><strong>Git Wrapper 拦截：</strong> 编写一个 git 命令的 wrapper 脚本或系统层面的 alias，拦截并禁止 <code>--no-verify</code> 参数的使用，或者在检测到该参数时强制报错，强迫 Agent 修复代码而非绕过检查。</p>\n</li>\n</ul>\n</li>\n</ul>\n"
  },
  {
    "slug": "langchain-to-langgraph",
    "title": "从 LangChain 到 LangGraph",
    "date": "2025-12-20T00:00:00.000Z",
    "tags": [
      "LangChain",
      "LangGraph",
      "Agent",
      "架构"
    ],
    "summary": "从大模型层/记忆层/工具层视角梳理 LangChain，并对比 LangGraph 的状态机式流程控制与可恢复性。",
    "cover": "/dark-minimalist-abstract-void-cosmos.jpg",
    "readingTime": 3,
    "contentHtml": "<p>以下观点是个人在学习中的思考，如果有不对的地方欢迎指正。<br>我会尽量从「设计框架」的视角来讲：每一层解决什么问题。</p>\n<h1>从 LangChain 到 LangGraph</h1>\n<h2>0. “智能体”的最终形态</h2>\n<ul>\n<li>单个智能体的理想形态：像人一样，能在环境里自动获取信息；主动规划怎么解决任务；会用工具做事；做完能反思要不要调整；需要调整就记住，方便下次更好地做。</li>\n<li>所以一个智能体框架最重要的三层：<code>大模型层</code>、<code>工具层</code>、<code>记忆层</code>。</li>\n</ul>\n<hr>\n<h2>1. 大模型层：我输入，它输出（但要先把“怎么问”整理好）</h2>\n<h3>1.1 大模型按功能的三种常见形态</h3>\n<ul>\n<li><code>Text LLM</code>（文本补全）：更像“续写器”，通常输入是一段纯文本。<ul>\n<li>你：请帮我翻译 HELLO</li>\n<li>模型：你好</li>\n</ul>\n</li>\n<li><code>Chat Model</code>（对话模型）：通常用 <code>messages</code> 来组织角色、历史消息（本质仍是 LLM，只是接口/训练方式更偏对话）。<ul>\n<li>你：你好吗  </li>\n<li>输入会被组织成：System / Human / AI（历史）…  </li>\n<li>模型：我很好</li>\n</ul>\n</li>\n<li><code>Embedding Model</code>（嵌入模型）：把文本变成浮点数向量，用来做检索/相似度。<ul>\n<li>你：你好</li>\n<li>模型：[0.1121, 0.4552]（这里只是举例）</li>\n</ul>\n</li>\n</ul>\n<p>简单理解就是：大模型像一个函数，你给它输入，它给你输出；不同类型主要是「输入输出的形态」和「适用场景」不一样。日常做 agent 绝大部分时候用的是对话模型。</p>\n<h3>1.2 大模型参数：告诉模型“怎么想”，以及“发给谁”</h3>\n<ul>\n<li>“发给谁”（连接/路由类参数）：<code>base_url</code> / <code>api_key</code> / <code>model</code>。</li>\n<li>“怎么想”（采样/长度类参数）：<code>temperature</code> / <code>max_tokens</code> / <code>top_p</code>（以及一些模型还会有其它控制项）。</li>\n</ul>\n<p>如果说我们的提示词是在说“思考什么”，那这些参数就在说“如何去思考”。</p>\n<h3>1.3 框架在大模型层要封装什么</h3>\n<p>至少要做两件事：<code>输入处理</code> + <code>请求发送</code>（以及对应的输出接收）。</p>\n<p>典型流程：\n<code>用户代码层（设置模型+参数） -&gt; LangChain SDK（存储参数/组装请求） -&gt; HTTP 客户端（发请求） -&gt; 模型服务（返回结果）</code></p>\n<p>用户层代码可能是：</p>\n<pre><code class=\"language-python\">response = llm.invoke(&quot;你好&quot;)\n\nchain = llm | StrOutputParser()\nresponse = chain.invoke(&quot;你好，请介绍一下人工智能&quot;)\n</code></pre>\n<p><code>invoke()</code> 大概做了这些事（伪代码）：</p>\n<pre><code class=\"language-text\">1) 把用户输入转换成模型需要的格式（尤其是 messages）\n2) 构建 HTTP 请求体（参数 + 输入）\n3) 构建 HTTP 请求头（认证等）\n4) POST 发出去，收结果\n</code></pre>\n<h3>1.4 LangChain 在大模型层的设计：Model I/O</h3>\n<p>LangChain 的 <code>Model I/O</code> 大致就是：输入怎么组织、输出怎么结构化。</p>\n<p><strong>输入处理</strong></p>\n<ul>\n<li><code>消息（messages）</code>：SystemMessage / HumanMessage / AIMessage / ToolMessage…（用来表达角色、历史、工具回传等）。</li>\n<li><code>提示词模板（prompt templates）</code>：当你不想每次手写“系统消息+历史+用户输入”时，就需要一个可复用、可注入变量的模板。<ul>\n<li><code>PromptTemplate</code>：普通文本模板，变量注入。</li>\n<li><code>ChatPromptTemplate</code>：生成 messages 列表的模板。</li>\n<li><code>XxxMessagePromptTemplate</code>：更细粒度的 message 模板（比如 System/Human 这类）。</li>\n<li><code>FewShotPromptTemplate</code>：放少量样例做示范（few-shot）。</li>\n</ul>\n</li>\n</ul>\n<p><strong>输出处理</strong></p>\n<ul>\n<li>模型很多时候只回字符串，但我们常常要结构化结果，所以需要 <code>OutputParser</code>（以及更严格的结构化输出方式）。</li>\n<li>常见做法是两步：<ol>\n<li>在提示词里先“约定输出格式”（比如 JSON 结构）。</li>\n<li>拿到输出后做解析/校验，不符合就再修一下（或者让模型重试）。</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h2>2. 记忆层</h2>\n<ul>\n<li>模型本身不会“记得”任何事情。短期记忆可以每次请求都附带历史消息，但历史越多，token 成本越高，也会拖慢响应。</li>\n</ul>\n<h3>2.1 LangChain 的一些经典短期记忆形态</h3>\n<ul>\n<li><code>ChatMessageHistory</code>：直接操作消息列表；重启就没了（不持久化）。</li>\n<li><code>ConversationBufferMemory</code>：全量对话都喂给模型，简单但很烧 token。</li>\n<li><code>ConversationBufferWindowMemory</code>：只保留最近 k 轮，对早期上下文会丢。</li>\n<li><code>ConversationSummaryMemory</code>：把历史总结成摘要，压缩 token。</li>\n<li><code>ConversationSummaryBufferMemory</code>：混合：最近窗口 + 更早摘要。</li>\n</ul>\n<p>（补一句：LangChain 新版本在“记忆”这块也有新写法/新推荐用法，但上面这些作为理解“记忆谱系”依然挺直观。）</p>\n<h3>2.2 长期记忆：RAG</h3>\n<p>短期记忆解决“刚刚聊过什么”，长期记忆更多解决“很久以前的知识/资料怎么召回”。最常见的技术就是 <code>RAG</code>。</p>\n<hr>\n<h2>3. 工具层：让模型能“动手”，而不是只会说</h2>\n<h3>3.1 Tool：工具从定义到执行</h3>\n<p>工具层是模型和外部世界交互的核心组件。我对 LangChain 的工具体系理解是：</p>\n<ul>\n<li>工具定义：用 <code>@tool</code>（或类似机制）定义工具的 <code>name/args/description/return</code>。</li>\n<li>工具绑定：把可用工具列表交给 agent/模型，让它知道能用哪些工具。</li>\n<li>工具调用：模型决定“要用哪个工具+参数是什么”（很多时候依赖 function calling/结构化调用）。</li>\n<li>工具执行：框架真的去调用工具，把结果回传给模型/状态。</li>\n</ul>\n<h3>3.2 MCP</h3>\n<p>如果说我们自己写的 tool 更像“我自己长出来的手脚”，那 <code>MCP（Model Context Protocol，由 Anthropic 提出）</code>更像“外接各种现成工具/资源的统一接口”。重点是：工具不一定是你写的，而是外部按协议提供的；你按协议去连、去用（常见是对接 MCP server 暴露的 tools/resources 等）。</p>\n<h3>3.3 RAG 也是一种“工具化能力”</h3>\n<p><code>RAG（检索增强生成）</code>经常被当作工具层的一部分能力：让模型在生成前先去“查”。</p>\n<p>完整流程是：</p>\n<ol>\n<li>文件处理：解析（各种格式提取文字）+ 切分（chunk）。</li>\n<li>入库：向量化（embedding）+ 写入向量库。</li>\n<li>用户提问：检索 -&gt; 把相关片段塞进上下文 -&gt; 生成回答。</li>\n</ol>\n<hr>\n<h2>4. 关于智能体的构建：Chain / LCEL 把步骤串起来</h2>\n<ul>\n<li><code>Chain</code>（链）这套思路很直观：把一步一步的操作组合起来，每一步都明确输入输出是什么。</li>\n<li>这其实就是一种“提示链模式”：复杂任务拆解成多个小步，然后串起来跑。</li>\n</ul>\n<p>LangChain 里常见的表达是 <code>LCEL（LangChain Expression Language）</code>，类似这样：</p>\n<pre><code class=\"language-python\"># 1. 导入所需组件\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_openai import ChatOpenAI\n\n# 2. 初始化模型\nchat_model = ChatOpenAI(\n    model=&quot;gpt-4&quot;,\n    temperature=0.7,\n    api_key=&quot;your-api-key-here&quot;,\n)\n\n# 3. 创建 JSON 输出解析器\njson_parser = JsonOutputParser()\n\n# 4. 创建提示词模板\nprompt_template = PromptTemplate(\n    template=&quot;&quot;&quot;请用简单的一句话描述一下什么是{name}？\n\n请严格按照以下格式输出：\n{format_instructions}\n\n描述：&quot;&quot;&quot;,\n    input_variables=[&quot;name&quot;],\n    partial_variables={&quot;format_instructions&quot;: json_parser.get_format_instructions()},\n)\n\n# 5. 使用 LCEL 构建链\nchain = prompt_template | chat_model | json_parser\n\n# 6. 调用链\nresponse = chain.invoke({&quot;name&quot;: &quot;反洗钱&quot;})\nprint(&quot;解析后的结构化数据：&quot;, response)\n</code></pre>\n<hr>\n<h2>5. LangGraph 解决的核心：把“黑盒 while”变成“可视的状态机”</h2>\n<h3>5.1 先说痛点：用 LangChain 也能写循环，但很容易变黑盒</h3>\n<p>（下面是伪代码，表达的是“痛点”，不是说 LangChain 只能这样写）</p>\n<pre><code class=\"language-python\">chat_history = []  # 必须手动维护的消息池\nmax_retries = 3\ncurrent_step = 0\n\nwhile current_step &lt; max_retries:\n    try:\n        response = agent_chain.invoke({&quot;input&quot;: &quot;查询天气&quot;, &quot;history&quot;: chat_history})\n\n        if response.is_error:\n            chat_history.append(ErrorMessage(content=response.error))\n            current_step += 1\n            continue\n        else:\n            save_to_db(chat_history)\n            break\n    except Exception:\n        print(&quot;系统崩溃，进度全丢&quot;)\n</code></pre>\n<p>这里能总结出几个问题：</p>\n<ol>\n<li>状态要你手动维护：每个 chain 都是相对独立的，你得自己在循环里喂 history、接结果、再塞回去。</li>\n<li>宕机恢复麻烦：状态在进程内存里，一崩就断点丢；要“可恢复”你得自己做持久化和恢复逻辑。</li>\n<li>可观测性弱：while 循环是黑盒，什么时候重试、卡在哪里、为什么跳转，很难一眼看出来。</li>\n</ol>\n<h3>5.2 LangGraph 的做法：全局状态 + 节点更新 + 检查点（快照）</h3>\n<p>我对 LangGraph 的理解是：</p>\n<ul>\n<li>你定义一个全局 <code>State</code>（通常就是字典/TypedDict），节点从 state 取需要的东西，执行完再把“更新”写回 state。</li>\n<li>引擎可以在每个节点之后做 <code>checkpoint</code>（快照），所以崩了也能从最后一次快照恢复。</li>\n<li>流程是“图”而不是“线性链+while”，所以路由/重试/并行这些逻辑更显式、更可视化。</li>\n</ul>\n<p>同样用伪代码表达一下（示意用法）：</p>\n<pre><code class=\"language-python\">class State(TypedDict):\n    messages: Annotated[list, add_messages]\n    retry_count: int\n\ndef call_agent(state: State):\n    return {&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;])]}\n\ndef call_tool(state: State):\n    return {\n        &quot;messages&quot;: [tool.invoke(...)],\n        &quot;retry_count&quot;: state[&quot;retry_count&quot;] + 1,\n    }\n\nworkflow = StateGraph(State)\nworkflow.add_node(&quot;agent&quot;, call_agent)\nworkflow.add_node(&quot;tool&quot;, call_tool)\n\nworkflow.add_conditional_edges(\n    &quot;tool&quot;,\n    should_retry,\n    {&quot;retry&quot;: &quot;agent&quot;, &quot;end&quot;: END},\n)\n\napp = workflow.compile(checkpointer=MemorySaver())\n</code></pre>\n<hr>\n<h2>6. LangGraph 的基础构件（词汇表）</h2>\n<ul>\n<li><code>State</code>：全局共享的数据结构（也是每一步的“快照内容”）；决定了信息怎么被保存、怎么被合并。</li>\n<li><code>Node</code>：节点，一个步骤/一个函数；理想情况下尽量小而清晰（不一定要求绝对无状态，但“单一职责”会更好维护）。</li>\n<li><code>Edge</code>：边，决定节点之间怎么连、按什么顺序执行；包括普通边和条件边（conditional）。</li>\n<li><code>Command / Send</code>：可以理解成“更强的流程控制能力”，比如显式跳转、并行派发子任务等（具体能力和写法要以版本为准）。</li>\n</ul>\n<h3>6.1 基本搭建流程</h3>\n<ol>\n<li>定义 <code>State</code>：决定全局状态类型，以及状态更新/合并规则（比如新值覆盖旧值，还是 append 到列表尾）。</li>\n<li>定义节点：<ul>\n<li>节点函数：接收 state，返回“要更新的字段”。</li>\n<li>条件函数：读取 state，返回下一步该走哪个节点。</li>\n</ul>\n</li>\n<li>组装图：<ul>\n<li><code>StateGraph(...)</code></li>\n<li><code>add_node(...)</code></li>\n<li>设入口/出口</li>\n<li>连线（普通边/条件边）</li>\n</ul>\n</li>\n<li>编译与运行：<ul>\n<li><code>compile(...)</code></li>\n<li>执行工作流</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2>7. 依旧关于 LangGraph 的“优化点”：并行、路由、反思、规划</h2>\n<p>Google 的《智能体设计模式》里提到很多模式（据说有 21 种），这里先收敛成一条“演化路线”：</p>\n<ol>\n<li>提示链模式：把复杂任务拆分。</li>\n<li>路由模式：根据输入/状态选择子模块。</li>\n<li>并行模式：任务更复杂时，性能优化会变成刚需。</li>\n<li>反思模式：做完能自评、能迭代。</li>\n<li>工具模式：突破训练数据的局限，让模型能动手。</li>\n<li>规划模式：让模型主动把任务拆成子任务。</li>\n</ol>\n<h3>7.1 路由这块：我对 LangChain vs LangGraph 的对比</h3>\n<p>先回顾一下 LangChain 路由（偏“固定流程”）：</p>\n<ol>\n<li>意图识别：用 LLM 对输入做分类（比如“怎么解方程” -&gt; 数学）。</li>\n<li>动态映射：配置一堆类似 if-else 的映射，把标签映射到提示词模板/子链。</li>\n<li>执行：按映射结果跑下去。</li>\n</ol>\n<p>问题是：逻辑路线本质上是事先固定的；而且很多时候每一步只是“产出数据”，很难做更复杂的流程控制（比如“发现风险就跳到某节点”，或者“拆成 5 个子任务并行”）。</p>\n<p>LangGraph 的路由更像“状态驱动 + 节点自治”：</p>\n<ul>\n<li>节点可以在更新 state 的同时，给出“下一步该去哪里”的指令（比如跳转到某节点）（ <code>Command</code>）。</li>\n<li>当 Agent 拆解出多个子任务时，可以把这些任务并行派发出去（<code>Send</code>）。并行分支一般会各自跑在隔离的状态副本上，跑完之后再按 state 的合并规则把结果汇总回主路径。</li>\n</ul>\n<p>所以结论还是：智能体的理想形态就是“像人一样”的那套流程（获取信息 -&gt; 规划 -&gt; 用工具 -&gt; 反思 -&gt; 记忆）。</p>\n<p>LangGraph 主要把这几个点“工程化”了：<code>路由更显式</code>、<code>并行更自然</code>、<code>反思/重试更可控</code>、<code>长流程更可恢复（checkpoint）</code>。<br>尤其是：当你不得不循环时，循环不能是黑盒；要可视化、可控、可恢复，最好还能把状态更新自动化。</p>\n<hr>\n<h2>8. 多智能体协作：从中心化到去中心化（为什么）</h2>\n<p>随着任务复杂度上涨，单智能体会碰天花板，多智能体的形态常见有：</p>\n<ul>\n<li>简单线性：AgentA -&gt; AgentB -&gt; end</li>\n<li>路由分发：用户输入 -&gt; 路由判断 -&gt; 特定 Agent</li>\n<li>中心化编排：主管 Agent 动态分配任务</li>\n<li>去中心化/网状协作：Agent 通过状态/指令自主触发协作</li>\n</ul>\n<p>“从中心化到去中心化”的核心原因：</p>\n<ul>\n<li>主管要吃掉所有反馈，提示词变得臃肿，幻觉风险会上升。</li>\n<li>通信链路变长：A 和 B 通信还得绕主管，延迟也会增加。</li>\n</ul>\n<p>LangGraph 这种“全局状态 + 显式流程控制”对去中心化更友好：通过共享状态让大家不偏航，也更可控。<br>更重要的一点是：如果去中心化吵起来陷入死循环，系统能中断，必要时人类介入接管。</p>\n"
  },
  {
    "slug": "sample-1",
    "title": "对抗虚无的方式",
    "date": "2024-01-15T00:00:00.000Z",
    "tags": [
      "哲学",
      "极简主义"
    ],
    "summary": "在无尽的黑暗中，我们能做的只是点燃一根火柴。即使明知它会熄灭，即使明知光芒微弱，但这微不足道的努力，正是我们存在的证明。",
    "cover": "/dark-minimalist-abstract-void-cosmos.jpg",
    "readingTime": 1,
    "contentHtml": "<p>在西西弗斯推石上山的神话中，加缪看到了人类存在的荒诞。石头永远会滚下来，努力永远不会有结果。但正是在这种明知不可能的坚持中，西西弗斯找到了自己的意义。</p>\n<h2>虚空的本质</h2>\n<p>我们生活在一个巨大的虚空中。宇宙的尺度让我们显得如此渺小，时间的长河让我们的生命显得如此短暂。在这样的背景下，个体的努力似乎毫无意义。</p>\n<p>但这正是极简主义的核心洞察：在巨大的虚空面前，我们不需要宏大的叙事，不需要复杂的装饰。我们需要的，是那一点点真实的、微不足道的努力。</p>\n<blockquote>\n<p>即使知道不可能，但仍然去做。</p>\n</blockquote>\n<h2>微光的意义</h2>\n<p>在黑暗中点燃一根火柴，光芒微弱，但它是真实的。这就是我们能做的全部，也是我们应该做的全部。不是因为它会改变世界，而是因为它证明了我们的存在。</p>\n<p>留白不是空无一物，而是给予思考的空间。负空间让我们能够看清那微弱的光芒。在极简的设计中，每一个元素都变得重要，每一个努力都变得可见。</p>\n<h2>持续的行动</h2>\n<p>这不是悲观主义，而是清醒的现实主义。我们接受虚无的存在，但不被它击败。我们继续写作，继续创造，继续在虚空中留下痕迹。</p>\n<p>就像西西弗斯推着石头，我们继续前行。不是因为相信终点，而是因为前行本身就是意义。</p>\n<h2>虚空中的痕迹</h2>\n<p>写作是一种对抗虚无的方式。每一个字，每一个句子，都是在黑暗中划出的一道光痕。它们微弱，但真实存在。它们短暂，但曾经发光。</p>\n<p>我们不追求永恒，因为永恒本身就是一个幻觉。我们追求的是此刻的真实，是当下的努力，是明知不可能却依然去做的勇气。</p>\n<p>这就是极简主义的终极意义：剥离一切装饰，直面虚空，然后在虚空中留下属于自己的微光。</p>\n"
  },
  {
    "slug": "sample-2",
    "title": "使用 Obsidian 和 Git 构建博客工作流",
    "date": "2024-01-10T00:00:00.000Z",
    "tags": [
      "工作流",
      "Obsidian"
    ],
    "summary": "极简主义不仅是设计哲学，更是一种工作方式。用最简单的工具构建高效的写作系统，让创作回归本质。",
    "cover": "/single-candle-flame-in-complete-darkness-minimalis.jpg",
    "readingTime": 1,
    "contentHtml": "<h2>为什么选择极简工作流</h2>\n<ul>\n<li>写作核心是内容，不是工具。工具越轻，摩擦越小。</li>\n<li>笔记即资产，最好存成纯文本，版本可追踪。</li>\n<li>发布应当自动化，减少重复劳动。</li>\n</ul>\n<h2>基本结构</h2>\n<pre><code>notes/        # Obsidian 里的原始 Markdown\nscripts/      # 同步/转换脚本\napp/posts/    # 站点的页面入口\ndata/posts.json # 由脚本生成，构建期读取\n</code></pre>\n<h2>操作步骤</h2>\n<ol>\n<li>在 Obsidian 里写作，按约定的 frontmatter（slug、title、date、tags、summary、cover）。</li>\n<li>运行同步脚本（本地或 CI）把 notes 转为 data/posts.json。</li>\n<li>Next.js 构建时读取 JSON，静态导出。</li>\n<li>GitHub Actions 自动部署到 Pages。</li>\n</ol>\n<h2>约定的 Frontmatter</h2>\n<ul>\n<li>slug: 页面路径，唯一，例如 <code>my-first-note</code></li>\n<li>title: 标题</li>\n<li>date: <code>YYYY-MM-DD</code></li>\n<li>tags: 数组</li>\n<li>summary: 简短摘要</li>\n<li>cover: 可选，指向 public 下图片路径</li>\n</ul>\n<h2>进一步优化</h2>\n<ul>\n<li>用阅读时长（词数/200）在列表展示。</li>\n<li>支持草稿：frontmatter 里 <code>draft: true</code> 时跳过导出。</li>\n<li>每次同步前校验必填字段，避免构建时才报错。</li>\n</ul>\n"
  },
  {
    "slug": "sample-3",
    "title": "留白的力量",
    "date": "2024-01-05T00:00:00.000Z",
    "tags": [
      "设计",
      "UI/UX"
    ],
    "summary": "负空间不是空无一物，而是给予思考的空间。在设计中，我们通过留白来强调重要的事物，在虚空中凸显微光。",
    "cover": "/vast-empty-dark-landscape-with-distant-light-horiz.jpg",
    "readingTime": 1,
    "contentHtml": "<h2>什么是留白</h2>\n<p>留白让信息有呼吸感。它不是空缺，而是有意的设计，帮助视线聚焦。</p>\n<h2>如何使用留白</h2>\n<ul>\n<li>聚焦：把关键元素周围腾出空间。</li>\n<li>分组：用间距而非线条来分隔。</li>\n<li>节奏：大留白带来缓冲，小留白带来紧凑。</li>\n</ul>\n<h2>留白与情绪</h2>\n<p>深色背景加柔和的光点，让情绪沉静；留白让这种情绪有回旋的余地。</p>\n<h2>行动建议</h2>\n<ol>\n<li>先决定层级，再放元素。</li>\n<li>不确定时，多给一点空间。</li>\n<li>让每个留白都有理由。</li>\n</ol>\n"
  }
]