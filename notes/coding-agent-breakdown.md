---
slug: coding-agent-breakdown
title: 关于对 Coding Agent 拆解和一些问题的汇总
date: 2026-01-19
tags:
  - Coding Agent
  - LLM
  - 最佳实践
  - 架构
summary: 梳理 LLM 的本质限制与 Coding Agent 的实现机制，并总结常见痛点与应对策略。
cover: /vast-empty-dark-landscape-with-distant-light-horiz.jpg
---

## 1. LLM 的本质限制与 Coding 领域的挑战

### 1.1 LLM 的本质

- **自回归生成 (Autoregressive Generation)**
    
    - 核心机制：根据 **"你的输入"** 和 **"前面生成的内容"** 预测概率最高的下一个 Token，然后不断循环直到结束。
        
    - **思考的局限性：** 没有独立的"思维黑盒"。尽管现在的大模型（如 o1/R1 类模型）有了显式的 reasoning（思维链）部分，依然无法脱离自回归范式——**必须通过生成 Token 才能进行思考**。
        
    - **记忆机制：** 上下文 (Context) 就是全部的记忆，没有隐藏的持久化存储。
        
- **Attention 机制 (注意力)**
    
    - **如何运行：** 每当生成一个 Token 时，都会计算当前位置与上下文 **每个位置** 的相关性（Q, K, V计算）。相关性高的获得更高权重，模型据此生成后续内容。
        
    - **上下文的诅咒：**
        
        - **计算复杂度：** 注意力机制的时间复杂度是 $O(n^2)$（不考虑优化算法时），随着长度增加计算量剧增。
            
        - **注意力稀释 (Lost in the Middle)：** 当上下文很长时，注意力权重会分散到更多位置，关键信息获得的权重可能会被稀释，导致“大海捞针”能力下降。所以并不是单纯增加 Context Window 就能解决所有问题。
            
- **强化学习 (Reinforcement Learning)**
    
    - **RLHF (Reinforcement Learning from Human Feedback)：** LLM 最初只学会了预测下一个 Token，需要通过 RL 让它学会“人类希望它怎么写”。
        
    - **流程：** 尝试（真实场景执行任务）-> 反馈（根据结果给回奖励/惩罚）-> 调整（使用 PPO/DPO 等算法调整模型参数）。
        

### 1.2 Coding 领域的特有问题

- **缺乏全局视野：** 由于自回归的本质，模型往往只关注“局部最优”的 Token 预测，缺乏对整个代码库的**全局规划 (Holistic Planning)**。
    
- **不可回溯性：** 流式输出导致无法“回头”修改已生成的内容。如果开头方向错了，后续只能基于错误的路径继续生成。
    
- **误差累积 (Error Accumulation)：** 在长任务中，如果某一步推理走偏，后续生成的代码会越来越偏离需求。
    
- **幻觉与严谨性的冲突：** Coding 要求强语法、强语义约束。LLM 无法像编译器一样对生成的代码有绝对认知，它只是在生成“看上去合理”的代码（除非通过测试或解释器提供明确的 Runtime 上下文）。
    

---

## 2. Coding Agent 的底层实现原理

### 2.1 基础架构

- **LLM API 结构：**
    
    - 消息数组包含角色：`system` (系统指令), `user` (用户输入), `assistant` (模型回答)。
        
    - **显式推理：** 对于具备推理能力的模型，API 响应中可能包含 `reasoning_content` 或 `thinking` 字段，与最终内容分开。
        
- **Tool Calling (工具调用/函数调用)：**
    
    - 模型不直接执行代码，而是生成结构化的 JSON 请求（工具调用）。
        
    - Agent 运行时（Runtime）拦截请求，执行工具，并将执行结果结构化为新消息（Role: `tool`）返回给模型。
        

### 2.2 性能优化：Prompt Caching

- **原理：** 在自回归生成中，如果每次请求都要重新处理整个 Input Context，会造成大量的计算浪费（Prefill 阶段）和高延迟。
    
- **前缀匹配 (Prefix Matching)：** 缓存通常基于前缀。只有当新请求的**开头部分**与之前请求**完全一致**时，才会命中缓存（KV Cache）。
    
- **最佳实践：**
    
    - **静态在前：** `System Prompt`, `Tool Definitions`, `Few-shot Examples` 等稳定内容放在 Prompt 最开头。
        
    - **动态在后：** 对话历史、当前用户输入、不断变化的文件内容放在后面，避免打断缓存的前缀连续性。
        

### 2.3 Agent Loop (ReAct 循环)

- **核心逻辑：** 调用模型 -> 检查是否需要使用工具 -> (若需要) 执行工具 -> 结果返回模型 -> 再次调用。
    
- **终止条件：**
    
    - `end_turn` / `stop`：模型认为任务已完成，输出最终响应。
        
    - `tool_use`：模型请求调用工具（循环继续）。
        
    - `max_tokens`：响应因达到长度限制被截断（通常需要处理这种异常）。
        

---

## 3. Coding Agent 常见痛点与解决方案

### 3.1 痛点一：会话之间无持久记忆

Agent 的工作往往需要跨越多个会话，默认情况下它会“失忆”。

- **解决方案：结构化任务追踪系统**
    
    - 要求 Agent 维护一组特定的 Markdown 文件（作为外部记忆）。
        
    - **必须包含：** 项目目标、背景、**当前正在进行的会话状态**、架构决策、技术栈、环境配置、依赖版本。
        
    - **强制动作：** 每次启动新会话时，强制 Agent 读取这些文件；结束时，强制更新这些文件。
        

### 3.2 痛点二：上下文窗口耗尽 (Context Exhaustion)

面对复杂任务，旧的历史消息会迅速填满 Context Window。

- **解决方案：**
    
    1. **观察压缩：** 只针对工具返回的 `Observation`（观察结果）进行处理。保留 Agent 的推理（Thought）和行动（Action），但将冗长的工具输出（如大文件的 `cat` 结果）用占位符替代。
        
    2. **LLM 摘要：** 定期将早期的观察、行动、推理全部压缩为一段摘要。（_注：可能会丢失细节_）
        
    3. **减少工具输出：** 优化工具设计，避免一次性返回 500行+ 的代码，改为按需读取（如 `read_lines`）。
        
    4. **简化工具结构：** 减少 Tool Definition 的 Token 占用。
        
    5. **任务拆分：** 将大任务拆解为子任务，每个子任务在一个新的、干净的 Context 中执行。
        

### 3.3 痛点三：选择性忽视问题

Agent 在工作中可能会通过日志或报错注意到各种潜在问题，但因为当前上下文空间紧张或聚焦于主任务，选择忽视。

- **解决方案：** 建立 **"发现即记录" (Log-as-you-go)** 的工作流程。强制 Agent 将发现的但暂不处理的问题写入外部的 `TODO.md` 或 `ISSUES.md`。
    

### 3.4 痛点四：过早宣布完成

Agent 可能会在大量 Corner Case 未覆盖的情况下自信地宣布任务结束。

- **解决方案：**
    
    - **外部计划检查：** 定期让 Agent 对照存储在上下文之外（文件里）的计划表。
        
    - **Definition of Done (DoD)：** 在 System Prompt 中植入严格的“完成定义”。
        

---

## 4. 策略：如何保证短对话的高效进行 (Iterative Development)

为了避免长上下文带来的“降智”，推荐采用**短周期迭代**模式：

- **对话 1 (Reconnaissance)：** 调研现有代码结构，输出关键文件列表和当前架构理解。不写代码，只读。
    
- **对话 2 (Foundation)：** 引用对话 1 的结论，实现基础功能/脚手架。
    
- **对话 3 (Refinement)：** 引用对话 2，增加边界条件处理和逻辑完善。
    
- **对话 4 (Testing)：** 引用对话 3，添加单元测试和集成测试。
    
- **对话 5 (Review)：** 自我代码审查，确认是否符合项目规范，检查安全隐患。
    
- **对话 6 (Fix)：** 针对审查发现的问题进行最终修复。
    

---

## 5. 最佳实践：项目上下文配置文件 

这是告诉 Agent "怎么在这个特定项目里工作" 的说明书。类似文件名：`CLAUDE.md` 或 `AGENT_GUIDE.md`。

### 内容结构 (原则：不超过 300 行)

- **WHAT（是什么）：**
    
    - 技术栈清单。
        
    - 项目结构树（特别是 Monorepo）。
        
    - 各模块职责：告诉 Agent 哪些是应用层，哪些是共享库。
        
- **WHY（为什么）：**
    
    - 项目的核心目的。
        
    - 关键设计决策的背景（Context）。
        
    - **历史债务说明：** 为什么有些代码看起来不合理？（防止 Agent 盲目重构导致破坏）。
        
- **HOW（怎么做）：**
    
    - 如何运行项目 (Run)。
        
    - 如何测试 (Test)。
        
    - 如何验证改动 (Verify)。
        
    - **具体命令：** 明确是用 `bun` 还是 `npm`？测试命令是 `make test` 还是 `npm test`？
        

> **💡 补充建议：**
> 
> - **代码风格 (Style)：** 忽略掉。不要在 Prompt 里教 LLM 怎么缩进，直接用 `Prettier` 或 `Linter` 工具在保存时自动格式化。
>     
> - **经验库：** 可以在文件中简要维护“踩过的坑”或“成功的模式”。
>     

---

## 6. 质量控制：防止 Agent 跳过测试

- **核心手段：**
    
    - 要求 Agent 频繁提交代码 (Small Commits)。
        
    - **Pre-commit Hooks：** 在 `.git/hooks/pre-commit` 中配置脚本，强制在 commit 前运行 Lint 和 Test。如果测试不通过，拒绝提交。
        
- **应对 Agent 的“小聪明”：**
    
    - Agent 可能会尝试使用 `git commit --no-verify` 来跳过检查。
        
    - **Git Wrapper 拦截：** 编写一个 git 命令的 wrapper 脚本或系统层面的 alias，拦截并禁止 `--no-verify` 参数的使用，或者在检测到该参数时强制报错，强迫 Agent 修复代码而非绕过检查。
        
